ggplot(data=as.data.frame(means), aes(means)) + geom_histogram() + xlab("1000 means of 40 exponentials (rate=0.2)") +
geom_vline(aes(xintercept=var(means)),color="blue", linetype="dashed", size=1, labels="var", show_guide=TRUE) +
annotate("text", x=0, y=-1.5, label=paste(" Variance: ",round(var(means),digits=2)),colour="blue", hjust=0) + scale_x_continuous(breaks=0:10)
ggplot(as.data.frame(means), aes(x=means)) + geom_density(alpha=.2, fill="#FF6666") + xlab("Means of 1000 exponential samples of size n = 4 and rate = 0.2") + scale_x_continuous(limits=c(0, 10), breaks=0:10)  +
stat_function(geom="geom_density",fun = dnorm, args = list(mean = mean(means), sd = sd(means)))
ggplot(as.data.frame(means), aes(x=means)) + geom_density(alpha=.2, fill="#FF6666") + xlab("Means of 1000 exponential samples of size n = 4 and rate = 0.2") + scale_x_continuous(limits=c(0, 10), breaks=0:10)  +
stat_function(geom="density",fun = dnorm, args = list(mean = mean(means), sd = sd(means)))
ggplot(as.data.frame(means), aes(x=means)) + geom_density(alpha=.2, fill="#FF6666") + xlab("Means of 1000 exponential samples of size n = 4 and rate = 0.2") + scale_x_continuous(limits=c(0, 10), breaks=0:10)  +
stat_function(geom="density",alpha=.2, fill="#FF6666",fun = dnorm, args = list(mean = mean(means), sd = sd(means)))
x <- c(0.18, -1.54, 0.42, 0.95)
mean(x)
x-mean(x)
(x-mean(x))^2
sum((x-mean(x))^2)
w <- c(2, 1, 3, 1)
sum(w*(x-mean(x))^2)
sum(w*(x-mean(x))^2)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
lm(y~x)
lm(x~y)
lm((x-mean(x))~(y-(mean(y)))
lm((x-mean(x))~(y-mean(y)))
lm((x-mean(x))~(y-mean(y)))
x-mean(x)
y-mean(y)
lm((x-mean(x))~(y-mean(y)))
data(mtcars)
lm(mtcars$mpg~mtcars$weight)
mtcars
lm(mtcars$mpg~mtcars$wt)
lm(mtcars$wt~mtcars(mpg))
lm(mtcars$wt~mtcars$mpg)
y-mean(y)
y
lm(x~(y-mean(y)))
y-mean(y)
y1 <- y-mean(y)
x1 <- x-mean(x)
lm(x1~y1)
lm(y1~x1)
normalize.vector(1,1)
library(normalize.vector)
install.packages("normalize.vector")
install.packages("normalize")
?scale
Fit the regression through the origin and get the slope treating y as the outcome and x as the regressor. (Hint, do not center the data since we want regression through the origin, not through the means of the data.)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
scale(x)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
scale(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
cor(x,y)*sd(y)/sd(x)
b1 <- cor(x,y)*sd(y)/sd(x)
b0 <- mean(y) - b1 * mean(x)
b0
lm(y~x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
lm(y ~ x)
summary(lm(y~x))
data(mtcars)
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x)
predict(fit,mean(x),interval = ("confidence"))
mean(x)
predict(fit,as.data.frame(mean(x)),interval = ("confidence"))
predict(fit,x,interval = ("confidence"))
predict(fit,mean(x),interval = ("confidence"))
x
predict(fit,1,interval = ("confidence"))
data.frame(x=c(mean(x)))
predict(fit,data.frame(x=c(mean(x))),interval = ("confidence"))
predict(fit,3.21725,interval = ("confidence"))
fit
37.285 + (-5.344 * mean(X))
37.285 + (-5.344 * mean(x))
predict(fit,data.frame(x=mean(x)),interval = ("confidence"))
predict(fit,data.frame(mean(x)),interval = ("confidence"))
predict(fit,data.frame(x=mean(x)),interval = ("confidence"))
predict(fit,as.data.frame(x=mean(x)),interval = ("confidence"))
predict(fit,data.frame(x=mean(x)),interval = ("confidence"))
x
predict(fit,data.frame(x=3,interval = ("confidence"))
predict(fit,data.frame(x=3),interval = ("confidence"))
predict(fit,data.frame(x=3),interval = ("prediction"))
x
xn <- x/2
xn
fitn <- lm(y~xn)
predict(fitn,data.frame(x=mean(xn)),interval = ("confidence"))
predict(fitn,data.frame(xn=mean(xn)),interval = ("confidence"))
xn <- x *2
fitn <- lm(y~xn)
predict(fitn,data.frame(xn=mean(xn)),interval = ("confidence"))
library(swirl)
swirl()
install_from_swirl("Regression Models")
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
lm(child~parent)
lm(child~parent,galton)
fit <- lm(child~parent,galton)
fit$residuals
summary(fit)
mean(fit$RESIDUALS)
mean(fit$residuals)
cov(fit$residuals,galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rrhs
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
verEst <- var(est)
verEst <- var(est(ols.slope,los.oc))
verEst <- var(est(ols.slope,los.ic))
d
d
v
est
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,sum(varRes,varEst))
all.equal(varChild,varRes+varEst)
efit <- lm(accel ~ mag+dist, attenu)
mean(res(efit))
mean(efit$residuals
)
cov(efit$residuals,attenu$mag)
cov(efit$residuals,attenu$dist)
cor(gpa_nor,gch_nor)
l_nor(gch_nor~gpa_nor)
l_nor(gch_nor~gpa_nor,gaulton)
lm(gch_nor~gpa_nor,gaulton)
lm(gch_nor~gpa_nor)
l_nor<-lm(gch_nor~gpa_nor)
data(mtcars)
x <- mtcars$am
y <- mtcars$mpg
cor(y, x)*sd(y)/sd(x)
cor(y,x)
cor(x,y)
data <- mtcars
datacols <- c("Miles/(US) gallon", "Number of cylinders", "Displacement (cu.in.)",
"Gross horsepower", "Rear axle ratio", "Weight (lb/1000)", "1/4 mile time",
"V/S", "Transmission (0 = automatic, 1 = manual)", "Number of forward gears",
"Number of carburetors")
variables <- cbind(datacols,colnames(data))
variables
lm(mpg ~ cyl, mtcars)
summary(fit_unadjusted)$coef
lm(mpg ~ am, mtcars)
lm(formula = mpg ~ am, data = mtcars)
data(mtcars)
reg1 <- lm(formula = mpg ~ am, data = mtcars)
summary(reg1)$coef
data(mtcars)
reg1 <- lm(formula = mpg ~ am, data = mtcars)
summary(reg1)$coef
data(mtcars)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)
summary(reg1)
data(mtcars)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
ggplot(mtcars, aes(x = am, y = mpg)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
library(ggplot2)
ggplot(mtcars, aes(x = am, y = mpg)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
summary(reg1)$adj.r.squared
data(mtcars)
mtcars$am <- factor(mtcars$am)
reg1 <- lm(formula = mpg ~ am, data = mtcars)
summary(reg1)$coef
summary(reg1)$adj.r.squared
ggplot(mtcars, aes(x = am, y = mpg)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(mtcars, aes(group1)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(mtcars, aes(group=1)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(mtcars, aes(group=1, y=mpg)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(mtcars, aes(x=group=1, y=mpg)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
data(mtcars)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
ggplot(mtcars, aes(x = am, y = mpg)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
data(mtcars)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
p1<-ggplot(aes(reg2$fitted, reg2$resid))+geom_point()
p1<-p1+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")
p1<-p1+xlab("Fitted values")+ylab("Residuals")
p1<-p1+ggtitle("Residual vs Fitted Plot")+theme_bw()
p1<-ggplot(aes(reg2$fitted, reg2$resid))+geom_point()
p1<-p1+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")
p1<-p1+xlab("Fitted values")+ylab("Residuals")
p1<-p1+ggtitle("Residual vs Fitted Plot")+theme_bw()
p1<-ggplot(reg2, aes(.fitted, .resid))+geom_point()
p1<-p1+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")
p1<-p1+xlab("Fitted values")+ylab("Residuals")
p1<-p1+ggtitle("Residual vs Fitted Plot")+theme_bw()
p1
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
ggplot(reg1, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
meanout <- data.frame(x=c(mean(mtcars$mpg)))
meanout
predict(reg2,meanout,interval = ("confidence"))
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
meanout <- data.frame(x=c(mean(mtcars$mpg)))
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
predict(reg2,meanout,interval = ("confidence"))
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
meanout <- data.frame(mean(mtcars$mpg))
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
predict(reg2,meanout,interval = ("confidence"))
reg2
mtcars$am
reg2 <- lm(formula = mtcars$mpg ~ mtcars$am + mtcars$disp + mtcars$hp + mtcars$wt,)
predict(reg2,meanout,interval = ("confidence"))
meanout <- data.frame(mean(mtcars$mpg))
predict(reg2,meanout,interval = ("confidence"))
meanout <- data.frame(x=c(mean(mtcars$mpg)))
predict(reg2,meanout,interval = ("confidence"))
meanout
predict(reg2,meanout,interval = ("confidence"))
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
predict(reg2,meanout,interval = ("confidence"))
attach=mtcars
predict(reg2,meanout,interval = ("confidence"))
confint(reg2, 'body.weight', level=0.95)
reg2
confint(reg2, 'body.weight', level=0.95)
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
meanout <- data.frame(x=c(mean(mtcars$mpg)))
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
predict(reg2,meanout,interval = ("confidence"))
confint(reg2, 'body.weight', level=0.95)
confint(reg2, 'mpg', level=0.95)
confint(reg2, 2, level=0.95)
confint(reg2, mean(mtcars$mpg) , level=0.95)
confint(reg2, mean(mtcars$mpg), level=0.95)
confint(reg2, 'mean(mtcars$mpg)', level=0.95)
confint(reg2, mtcars$mpg, level=0.95)
confint(reg2, mpg, level=0.95)
confint(reg2, $mpg, level=0.95)
confint(reg2, .mpg, level=0.95)
confint(reg2, , level=0.95)
confint(reg2, , level=0.95)
confint(reg2,"mpg" , level=0.95)
confint(reg2,, level=0.95)
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
meanout <- data.frame(x=c(mean(mtcars$mpg)))
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
lm(formula = mpg ~ disp + hp + wt + am, data = mtcars)
p <- predict(reg2,meanout,interval = ("confidence"))
y <- mtcars$mpg
x <- mtcars$am
x2 <- mtcars$disp
x3 <- mtcars$hp
h4 <- mtcars$wt
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
reg2
p <- predict(reg2,meanout,interval = ("confidence"))
reg2 <- lm(y ~ x + x2 + x3 + x4)
y <- mtcars$mpg
x <- mtcars$am
x2 <- mtcars$disp
x3 <- mtcars$hp
x4 <- mtcars$wt
reg2 <- lm(y ~ x + x2 + x3 + x4)
reg2
p <- predict(reg2,meanout,interval = ("confidence"))
data.frame(x=c(mean(mtcars$mpg)))
predict(reg2,20.09062,interval = ("confidence"))
predict(reg2,2,interval = ("confidence"))
predict(reg2,20,interval = ("confidence"))
predict(reg2,data.frame(x=mean(mtcars$mpg)),interval = ("confidence"))
predict(reg2,data.frame(x=20,interval = ("confidence"))
_
predict(reg2,data.frame(x=20,interval = ("confidence")))
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
predict(reg2,data.frame(x=mean(mtcars$mpg)),interval = ("confidence"))
predict(reg1,data.frame(x=mean(mtcars$mpg)),interval = ("confidence"))
predict(reg2,data.frame(x=20),interval = ("confidence"))
predict(reg2,2,interval = ("confidence"))
predict(reg2,newdata=data.frame(x=20),interval = ("confidence"))
predict(reg2,newdata=data.frame(x=20),interval = ("confidence"))
predict(reg2,newdata=data.frame(am=20),interval = ("confidence"))
predict(reg2,newdata=data.frame(am + disp + hp + wt=20),interval = ("confidence"))
predict(reg2,newdata=data.frame((am + disp + hp + wt)=20),interval = ("confidence"))
predict(reg2,newdata=data.frame(x=20),interval = ("confidence"))
library(ggplot2)
data(mtcars)
mtcars$am <- factor(mtcars$am)
reg2 <- lm(formula = mpg ~ am + disp + hp + wt, data = mtcars)
summary(reg2)$coef
summary(reg2)$adj.r.squared
ggplot(reg2, aes(.fitted, .resid))+geom_point()+stat_smooth(method="loess")+geom_hline(yintercept=0, col="red", linetype="dashed")+xlab("Fitted values")+ylab("Residuals")+ggtitle("Residual vs Fitted Plot")+theme_bw()
confint(reg2, , level=0.95)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
testing1 <- read.table("pml-testing.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
testing <- testing1[,colSums(is.na(testing1))==0]
testing <- testing[,c(-1,-2,-3,-4,-5,-6,-7)]
set.seed(12345)
#modelfit <- train(classe ~.,preProcess=c("center","scale","pca"),method="rf",data=training[sample(nrow(training), 1000), ],prox=TRUE) #78% accuracy
modelfit <- train(classe ~.,method="rf",preProcess=c("pca"),data=training[sample(nrow(training), 1000), ],prox=TRUE) #second try, 91% accuracy
print(modelfit)
predictions <- predict(modelfit,newdata=training)
confusionMatrix(predictions,training$classe)
modelfit <- train(classe ~.,method="rf",data=training[sample(nrow(training), 1000), ],prox=TRUE) #second try, 91% accuracy
predictions <- predict(modelfit,newdata=testing)
testing
predictions
answers <- predictions
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
print(modelfit)
predictions <- predict(modelfit,newdata=training)
confusionMatrix(predictions,training$classe)
memory.limit(size=8000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
inTrain <- createDataPartition(y=training$classe, p=0.6,list=FALSE)
training <- training[inTrain,]
test <- spam[-inTrain,]
memory.limit(size=4000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
inTrain <- createDataPartition(y=training$classe, p=0.6,list=FALSE)
training <- training[inTrain,]
test <- training[-inTrain,]
summary(training)
training
set.seed(12345)
modelfit <- train(classe ~.,method="rf",data=training,trControl=trainControl(method="cv"),preProcess=c("center","scale","pca"),prox=TRUE)
warnings()
str(training)
training1
memory.limit(size=13000)
memory.limit(size=4000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
testing1 <- read.table("pml-testing.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
testing <- testing1[,colSums(is.na(testing1))==0]
testing <- testing[,c(-1,-2,-3,-4,-5,-6,-7)]
inTrain <- createDataPartition(y=training[sample(nrow(training), 5000), ]$classe, p=0.6,list=FALSE)
training <- training[inTrain,]
test <- training[-inTrain,]
training
str(training)
inTrain <- createDataPartition(y=training[sample(nrow(training), 10000), ]$classe, p=0.6,list=FALSE)
training <- training[inTrain,]
test <- training[-inTrain,]
memory.limit(size=4000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
testing1 <- read.table("pml-testing.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
testing <- testing1[,colSums(is.na(testing1))==0]
testing <- testing[,c(-1,-2,-3,-4,-5,-6,-7)]
memory.limit(size=4000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
testing1 <- read.table("pml-testing.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
testing <- testing1[,colSums(is.na(testing1))==0]
testing <- testing[,c(-1,-2,-3,-4,-5,-6,-7)]
memory.limit(size=4000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
testing1 <- read.table("pml-testing.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
testing <- testing1[,colSums(is.na(testing1))==0]
testing <- testing[,c(-1,-2,-3,-4,-5,-6,-7)]
inTrain <- createDataPartition(y=training[sample(nrow(training), 10000), ]$classe, p=0.6,list=FALSE)
training <- training[inTrain,]
test <- training[-inTrain,]
modelfit <- train(classe ~.,method="rf",data=training,trControl=trainControl(method="cv"),preProcess=c("center","scale","pca"),prox=TRUE)
memory.limit(size=4000)
library(caret)
library(ggplot2)
setwd("C:\\Users\\ElitebookHP\\Desktop\\coursera_machLearning")
training1 <- read.table("pml-training.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
training <- training1[,colSums(is.na(training1))==0]
training <- training[,c(-1,-2,-3,-4,-5,-6,-7)]
training$classe <- as.factor(training$classe)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,c(row.names(nsv[nsv$nzv==FALSE,]))]
testing1 <- read.table("pml-testing.csv",as.is = TRUE, na.strings=c("NA", "-", "?","","#DIV/0!"),sep = ",",header = TRUE)
testing <- testing1[,colSums(is.na(testing1))==0]
testing <- testing[,c(-1,-2,-3,-4,-5,-6,-7)]
inTrain <- createDataPartition(y=training[sample(nrow(training), 1000), ]$classe, p=0.6,list=FALSE)
training <- training[inTrain,]
test <- training[-inTrain,]
modelfit <- train(classe ~.,method="rf",data=training,trControl=trainControl(method="cv"),preProcess=c("center","scale","pca"),prox=TRUE)
modelfit <- train(classe ~.,method="rf",data=training[sample(nrow(training), 1000), ],prox=TRUE) #second try, 91% accuracy
modelfit <- train(classe ~.,method="rf",data=training[sample(nrow(training), 100), ],prox=TRUE) #second try, 91% accuracy
